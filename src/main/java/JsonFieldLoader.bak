/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.meta.pigudf;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.InputFormat;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.lib.input.LineRecordReader;
import org.apache.pig.LoadFunc;
import org.apache.pig.PigException;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigFileInputFormat;
import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigSplit;
import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DefaultBagFactory;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.codehaus.jackson.JsonNode;
import org.codehaus.jackson.JsonParseException;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.node.ArrayNode;
import org.codehaus.jackson.node.ObjectNode;
import org.codehaus.jackson.node.ValueNode;
import org.codehaus.jackson.JsonParser;

import java.io.IOException;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;
import java.util.Stack;

/**
 * Parses JSON data from a JSON file one line at a time. Each line is expected
 * to contain a separate JSON record.
 *
 * Generates a Tuple from the named fields.
 *
 * Usage:
 * e.g. JSON that looks like:
 * --------------------------------------------------------------
 * {"menu": {
 *    "id": "file",
 *    "value": "File",
 *    "popup": {
 *      "menuitem": [
 *        {"value": "New", "onclick": "CreateNewDoc()"},
 *        {"value": "Open", "onclick": "OpenDoc()"},
 *        {"value": "Close", "onclick": "CloseDoc()"}
 *      ]
 *    }
 * }}
 * --------------------------------------------------------------
 * **The above json record is expanded for readability. This entire record should be
 * condensed to one line in your json file.
 *
 *  register the jar containing this class (e.g. piggybank.jar)
 *  a = load '/tmp/jsontest' using com.meta.pigudf.JsonFieldLoader("field1) as ();
 *  b = foreach a generate flatten(json#'menu') as menu;
 *  c = foreach b generate flatten(menu#'popup') as popup;
 *  d = foreach c generate flatten(popup#'menuitem') as menu;
 *  e = foreach d generate flatten(men#'value') as val;
 *
 */
public class JsonLoader extends LoadFunc {
    private static final TupleFactory tupleFactory = TupleFactory.getInstance();
	private static final JsonFactory jsonFactory = new JsonFactory();

	private List<String[]> fieldPaths;
    private LineRecordReader in = null;

    public JsonLoader(String fields) {
        super();
		if (fields == null)
			throw new IllegalArgumentException("Must specify comma separated list of JSON paths to load");

		fieldPaths = new ArrayList<String[]>();
		for (String p : fields.split(",")) {
			fieldPaths.add(p.trim().split("\\."));
		}
		if (fieldPaths.size() == 0)
			throw new IllegalArgumentException("Must specify comma separated list of JSON paths to load");

        //mapper = new ObjectMapper();
        //mapper.configure(JsonParser.Feature.ALLOW_UNQUOTED_FIELD_NAMES, true);
    }

    @SuppressWarnings("unchecked")
    @Override
    public InputFormat getInputFormat() throws IOException {
        return new PigTextInputFormat();
    }

    /**
     * Only return null if there is no more input in this file!
     */
    @Override
    public Tuple getNext() throws IOException {
		try {
			if (in.nextKeyValue()) {
				Text val = in.getCurrentValue();
				if (val != null) {
					return parse(jsonFactory.createJsonParser(val.getBytes(),
															  0,
															  val.getLength()));
				}
			}
		} catch (JsonParseException ex) {
			// ignore
		}
		return null;
    }

	// here for performance
	private jsonPosition = new Stack<String>();

    protected Tuple parse(JsonParser json) throws IOException {
		JsonToken t = json.nextToken();
		int depth = 0;
		while (t != null || json.isClosed()) {
			switch (t) {
			case JsonToken.START_OBJECT:
				String objectName = json.getCurrentName();
				depth++;
				// check if any fieldPaths(depth) contain objectName
				// if not, skip this object
				// if yes, keep going


		if (null == json.nextToken

        try {
            return tupleFactory.newTuple(walkObject(mapper.readTree(line)));
        } catch (NumberFormatException e) {
            int errCode = 6018;
            String errMsg = "Error while reading input - Very big number exceeds the scale of long: " + line;
            throw new ExecException(errMsg, errCode, PigException.REMOTE_ENVIRONMENT, e);
        } catch (JsonParseException e) {
            return tupleFactory.newTuple(0); // JSON parsing errors yield empty tuple
        }
    }


    @SuppressWarnings("unchecked")
    @Override
    public void prepareToRead(RecordReader reader, PigSplit split) throws IOException {
        in = (LineRecordReader) reader;
    }

    @Override
    public void setLocation(String location, Job job) throws IOException {
        PigFileInputFormat.setInputPaths(job, location);
    }
}